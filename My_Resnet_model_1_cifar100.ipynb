{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My-Resnet-model-1-cifar100.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandkc812/Classification_proj/blob/master/My_Resnet_model_1_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NegDQ2Mwbsh",
        "colab_type": "code",
        "outputId": "37feb4ab-6089-45a5-9d4e-8bac2ff47cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras import backend\n",
        "\n",
        "import keras\n",
        "from keras import applications\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiL4uLBAwjJk",
        "colab_type": "code",
        "outputId": "6dbf2b72-ba3e-49e3-cd2a-e2995e66ab1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "print('Loading Cifar100 train+test done')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "Loading Cifar100 train+test done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKKlbUmFjy8",
        "colab_type": "code",
        "outputId": "8ab18024-3b64-4b25-a076-0e202cd5a6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#from keras.models  import Sequential\n",
        "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "#from tensorflow.python.keras.applications import ResNet50\n",
        "\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "\n",
        "\n",
        "num_classes=100\n",
        "#------------------BUILD MODEL- 2 with lowernumber of layers---------------------------------\n",
        "\n",
        "#y_train_cat = keras.utils.to_categorical(y_train, num_classes=num_classes, dtype='float32')\n",
        "y_train_cat = keras.utils.to_categorical(y_train, num_classes=num_classes, dtype='float32')\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes=num_classes, dtype='float32')\n",
        "\n",
        "NUM_CLASSES = 100\n",
        "#resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "resnet_weights_path = 'imagenet'\n",
        "\n",
        "\n",
        "#model.layers[0].trainable = False\n",
        "model = Sequential()\n",
        "\n",
        "resnet_layer =  ResNet50(include_top = False, pooling = 'avg', weights = resnet_weights_path)\n",
        "\n",
        "\n",
        "resnet_output = model.add(resnet_layer)\n",
        "\n",
        "# track the inputs to the first layer\n",
        "inputs = model.layers[0].inputs\n",
        "\n",
        "class_layer  = (Dense(NUM_CLASSES, activation = 'sigmoid', name='class_layer'))\n",
        "\n",
        "outputs = model.add(class_layer)\n",
        "\n",
        "\n",
        "# Create original model and save it\n",
        "\n",
        "#model.load_weights(resnet_weights_path)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print('\\033[1;37;45m RESNET model- backend  ')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "class_layer (Dense)          (None, 100)               204900    \n",
            "=================================================================\n",
            "Total params: 23,792,612\n",
            "Trainable params: 23,739,492\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "\u001b[1;37;45m RESNET model- backend  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aSBvW9aVu9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#=========================NO AUGMENTATION=============================\n",
        "#=========================NO AUGMENTATION=============================\n",
        "#=========================NO AUGMENTATION=============================\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "weights_file = '/content/gdrive/My Drive/Colab Notebooks/MyCifar100/myresnet_cf100_model_1.h5'\n",
        "history_file = '/content/gdrive/My Drive/Colab Notebooks/MyCifar100/myresnet_cf100_model_1.csv'\n",
        "\n",
        "exists = os.path.isfile(weights_file)\n",
        "if exists:\n",
        "    # Append mode \n",
        "    start_range =2 \n",
        "    model.load_weights(weights_file)\n",
        "    print('File exists, load weights....',weights_file)\n",
        "else:\n",
        "    #Start New afresh\n",
        "    print('File Does not exists, start new ')\n",
        "    start_range =1\n",
        "    \n",
        "    \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "for iter in range(start_range,50):\n",
        "        print(\"---------------------Epoch :: \", iter) \n",
        "        crn50_ = model.fit(x=x_train, y=y_train_cat, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test_cat), shuffle=True)\n",
        "\n",
        "\n",
        "        model.save(weights_file)\n",
        "        print('Completed saving weights iter', iter)\n",
        "\n",
        "        \n",
        "        if iter==1:\n",
        "            pd.DataFrame(crn50_.history).to_csv(history_file, mode='w', header=True)\n",
        "        else:\n",
        "            pd.DataFrame(crn50_.history).to_csv(history_file, mode='a', header=False)\n",
        "        \n",
        "        print(\"saved History iter\", iter)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeRlm3HQRYGt",
        "colab_type": "code",
        "outputId": "b2b1c36e-f5d9-4fdd-b0ad-712972cd9dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5304
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#-------------------WITH DATA AUGMENTATION----------------------------------------------------\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "weights_file = '/content/gdrive/My Drive/Colab Notebooks/MyCifar100/myresnet_cf100_temp.h5'\n",
        "history_file = '/content/gdrive/My Drive/Colab Notebooks/MyCifar100/myresnet_cf100_model_3a_aug.csv'\n",
        "EPOCHS = 2\n",
        "BS = 32\n",
        "\n",
        "\n",
        "exists = os.path.isfile(weights_file)\n",
        "if exists:\n",
        "    # Append mode \n",
        "    start_range =2 \n",
        "    model.load_weights(weights_file)\n",
        "    print('File exists, load weights....',weights_file)\n",
        "else:\n",
        "    #Start New afresh\n",
        "    print('File Does not exists, start new ')\n",
        "    start_range =1\n",
        "    \n",
        "\n",
        " \n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rescale=1./255,rotation_range=45, zoom_range=0.4,\n",
        "\twidth_shift_range=0.4, height_shift_range=0.4, shear_range=0.25,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        " \n",
        "testaug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "for iter in range(start_range,50):\n",
        "        print(\"---------------------Epoch :: \", iter) \n",
        "        # train the network\n",
        "        #crn50_ = model.fit(x=x_train, y=y_train_cat, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test_cat), shuffle=True)\n",
        "\n",
        "        crn50_ = model.fit_generator(aug.flow(x_train, y_train_cat, batch_size=BS),\n",
        "          validation_data=testaug.flow(x_test, y_test_cat, batch_size=BS), steps_per_epoch=len(x_train) // BS,\n",
        "          epochs=EPOCHS, validation_steps =len(x_test)//BS )\n",
        "        \n",
        "        model.save(weights_file)\n",
        "        print('Completed saving weights iter', iter)\n",
        "\n",
        "        \n",
        "        if iter==1:\n",
        "            pd.DataFrame(crn50_.history).to_csv(history_file, mode='w', header=True)\n",
        "        else:\n",
        "            pd.DataFrame(crn50_.history).to_csv(history_file, mode='a', header=False)\n",
        "        \n",
        "        print(\"saved History iter\", iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "File Does not exists, start new \n",
            "---------------------Epoch ::  1\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 3.9892 - acc: 0.0941\n",
            "1563/1563 [==============================] - 118s 75ms/step - loss: 4.3864 - acc: 0.0451 - val_loss: 3.9892 - val_acc: 0.0941\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 3.4915 - acc: 0.1785\n",
            "1563/1563 [==============================] - 111s 71ms/step - loss: 3.8613 - acc: 0.1073 - val_loss: 3.4915 - val_acc: 0.1785\n",
            "Completed saving weights iter 1\n",
            "saved History iter 1\n",
            "---------------------Epoch ::  2\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 3.0198 - acc: 0.2671\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 3.4824 - acc: 0.1719 - val_loss: 3.0198 - val_acc: 0.2671\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.8840 - acc: 0.2966\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 3.2011 - acc: 0.2237 - val_loss: 2.8840 - val_acc: 0.2966\n",
            "Completed saving weights iter 2\n",
            "saved History iter 2\n",
            "---------------------Epoch ::  3\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.6979 - acc: 0.3245\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 2.9961 - acc: 0.2590 - val_loss: 2.6979 - val_acc: 0.3245\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.6896 - acc: 0.3371\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 2.8635 - acc: 0.2845 - val_loss: 2.6896 - val_acc: 0.3371\n",
            "Completed saving weights iter 3\n",
            "saved History iter 3\n",
            "---------------------Epoch ::  4\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.4663 - acc: 0.3777\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 2.7474 - acc: 0.3077 - val_loss: 2.4663 - val_acc: 0.3777\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.4262 - acc: 0.3792\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 2.6620 - acc: 0.3207 - val_loss: 2.4262 - val_acc: 0.3792\n",
            "Completed saving weights iter 4\n",
            "saved History iter 4\n",
            "---------------------Epoch ::  5\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.2866 - acc: 0.4088\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.5910 - acc: 0.3376 - val_loss: 2.2866 - val_acc: 0.4088\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.4547 - acc: 0.3906\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.5204 - acc: 0.3500 - val_loss: 2.4547 - val_acc: 0.3906\n",
            "Completed saving weights iter 5\n",
            "saved History iter 5\n",
            "---------------------Epoch ::  6\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.6829 - acc: 0.3624\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.4733 - acc: 0.3628 - val_loss: 2.6829 - val_acc: 0.3624\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.4882 - acc: 0.3851\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.4220 - acc: 0.3704 - val_loss: 2.4882 - val_acc: 0.3851\n",
            "Completed saving weights iter 6\n",
            "saved History iter 6\n",
            "---------------------Epoch ::  7\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2910 - acc: 0.4157\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.3687 - acc: 0.3775 - val_loss: 2.2910 - val_acc: 0.4157\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.5239 - acc: 0.3981\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.3171 - acc: 0.3866 - val_loss: 2.5239 - val_acc: 0.3981\n",
            "Completed saving weights iter 7\n",
            "saved History iter 7\n",
            "---------------------Epoch ::  8\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.2715 - acc: 0.4326\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.2872 - acc: 0.3959 - val_loss: 2.2715 - val_acc: 0.4326\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.0741 - acc: 0.4681\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 2.2376 - acc: 0.4080 - val_loss: 2.0741 - val_acc: 0.4681\n",
            "Completed saving weights iter 8\n",
            "saved History iter 8\n",
            "---------------------Epoch ::  9\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.1648 - acc: 0.4497\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 2.2180 - acc: 0.4105 - val_loss: 2.1648 - val_acc: 0.4497\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.4407 - acc: 0.4188\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 2.1863 - acc: 0.4170 - val_loss: 2.4407 - val_acc: 0.4188\n",
            "Completed saving weights iter 9\n",
            "saved History iter 9\n",
            "---------------------Epoch ::  10\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1692 - acc: 0.4538\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 2.1555 - acc: 0.4275 - val_loss: 2.1692 - val_acc: 0.4538\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.4100 - acc: 0.4270\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 2.1129 - acc: 0.4334 - val_loss: 2.4100 - val_acc: 0.4270\n",
            "Completed saving weights iter 10\n",
            "saved History iter 10\n",
            "---------------------Epoch ::  11\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2473 - acc: 0.4434\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 2.0954 - acc: 0.4370 - val_loss: 2.2473 - val_acc: 0.4434\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.5545 - acc: 0.4003\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 2.0691 - acc: 0.4411 - val_loss: 2.5545 - val_acc: 0.4003\n",
            "Completed saving weights iter 11\n",
            "saved History iter 11\n",
            "---------------------Epoch ::  12\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3140 - acc: 0.4541\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 2.0358 - acc: 0.4503 - val_loss: 2.3140 - val_acc: 0.4541\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.0533 - acc: 0.4814\n",
            "1563/1563 [==============================] - 107s 69ms/step - loss: 2.0096 - acc: 0.4581 - val_loss: 2.0533 - val_acc: 0.4814\n",
            "Completed saving weights iter 12\n",
            "saved History iter 12\n",
            "---------------------Epoch ::  13\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.0742 - acc: 0.4688\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.9881 - acc: 0.4594 - val_loss: 2.0742 - val_acc: 0.4688\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.3223 - acc: 0.4488\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.9665 - acc: 0.4683 - val_loss: 2.3223 - val_acc: 0.4488\n",
            "Completed saving weights iter 13\n",
            "saved History iter 13\n",
            "---------------------Epoch ::  14\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.1725 - acc: 0.4636\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.9403 - acc: 0.4709 - val_loss: 2.1725 - val_acc: 0.4636\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.1040 - acc: 0.4789\n",
            "1563/1563 [==============================] - 110s 71ms/step - loss: 1.9215 - acc: 0.4769 - val_loss: 2.1040 - val_acc: 0.4789\n",
            "Completed saving weights iter 14\n",
            "saved History iter 14\n",
            "---------------------Epoch ::  15\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.2631 - acc: 0.4655\n",
            "1563/1563 [==============================] - 110s 71ms/step - loss: 1.8918 - acc: 0.4823 - val_loss: 2.2631 - val_acc: 0.4655\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.0339 - acc: 0.4948\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.8800 - acc: 0.4845 - val_loss: 2.0339 - val_acc: 0.4948\n",
            "Completed saving weights iter 15\n",
            "saved History iter 15\n",
            "---------------------Epoch ::  16\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.1067 - acc: 0.4791\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.8634 - acc: 0.4871 - val_loss: 2.1067 - val_acc: 0.4791\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.4682 - acc: 0.4287\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.8454 - acc: 0.4906 - val_loss: 2.4682 - val_acc: 0.4287\n",
            "Completed saving weights iter 16\n",
            "saved History iter 16\n",
            "---------------------Epoch ::  17\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.0767 - acc: 0.4941\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.8217 - acc: 0.4965 - val_loss: 2.0767 - val_acc: 0.4941\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 2.1151 - acc: 0.4818\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 1.8081 - acc: 0.5024 - val_loss: 2.1151 - val_acc: 0.4818\n",
            "Completed saving weights iter 17\n",
            "saved History iter 17\n",
            "---------------------Epoch ::  18\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1037 - acc: 0.4882\n",
            "1563/1563 [==============================] - 109s 70ms/step - loss: 1.7889 - acc: 0.5047 - val_loss: 2.1037 - val_acc: 0.4882\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1472 - acc: 0.4809\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 1.7646 - acc: 0.5117 - val_loss: 2.1472 - val_acc: 0.4809\n",
            "Completed saving weights iter 18\n",
            "saved History iter 18\n",
            "---------------------Epoch ::  19\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.5594 - acc: 0.4300\n",
            "1563/1563 [==============================] - 108s 69ms/step - loss: 1.7408 - acc: 0.5169 - val_loss: 2.5594 - val_acc: 0.4300\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.6843 - acc: 0.4014\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 1.7367 - acc: 0.5184 - val_loss: 2.6843 - val_acc: 0.4014\n",
            "Completed saving weights iter 19\n",
            "saved History iter 19\n",
            "---------------------Epoch ::  20\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2851 - acc: 0.4650\n",
            "1563/1563 [==============================] - 107s 68ms/step - loss: 1.7132 - acc: 0.5241 - val_loss: 2.2851 - val_acc: 0.4650\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.0623 - acc: 0.5044\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 1.7023 - acc: 0.5240 - val_loss: 2.0623 - val_acc: 0.5044\n",
            "Completed saving weights iter 20\n",
            "saved History iter 20\n",
            "---------------------Epoch ::  21\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2247 - acc: 0.4809\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.6820 - acc: 0.5284 - val_loss: 2.2247 - val_acc: 0.4809\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2320 - acc: 0.4884\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.6652 - acc: 0.5327 - val_loss: 2.2320 - val_acc: 0.4884\n",
            "Completed saving weights iter 21\n",
            "saved History iter 21\n",
            "---------------------Epoch ::  22\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1206 - acc: 0.4968\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.6438 - acc: 0.5386 - val_loss: 2.1206 - val_acc: 0.4968\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1811 - acc: 0.4902\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.6344 - acc: 0.5406 - val_loss: 2.1811 - val_acc: 0.4902\n",
            "Completed saving weights iter 22\n",
            "saved History iter 22\n",
            "---------------------Epoch ::  23\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1449 - acc: 0.4929\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.6147 - acc: 0.5470 - val_loss: 2.1449 - val_acc: 0.4929\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2389 - acc: 0.4739\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 1.6062 - acc: 0.5476 - val_loss: 2.2389 - val_acc: 0.4739\n",
            "Completed saving weights iter 23\n",
            "saved History iter 23\n",
            "---------------------Epoch ::  24\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.0783 - acc: 0.5054\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 1.5881 - acc: 0.5564 - val_loss: 2.0783 - val_acc: 0.5054\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3726 - acc: 0.4718\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.5768 - acc: 0.5551 - val_loss: 2.3726 - val_acc: 0.4718\n",
            "Completed saving weights iter 24\n",
            "saved History iter 24\n",
            "---------------------Epoch ::  25\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.0218 - acc: 0.5217\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.5517 - acc: 0.5593 - val_loss: 2.0218 - val_acc: 0.5217\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2591 - acc: 0.4888\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.5434 - acc: 0.5617 - val_loss: 2.2591 - val_acc: 0.4888\n",
            "Completed saving weights iter 25\n",
            "saved History iter 25\n",
            "---------------------Epoch ::  26\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1779 - acc: 0.4956\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.5329 - acc: 0.5649 - val_loss: 2.1779 - val_acc: 0.4956\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.4849 - acc: 0.4585\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.5158 - acc: 0.5700 - val_loss: 2.4849 - val_acc: 0.4585\n",
            "Completed saving weights iter 26\n",
            "saved History iter 26\n",
            "---------------------Epoch ::  27\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1568 - acc: 0.4981\n",
            "1563/1563 [==============================] - 106s 68ms/step - loss: 1.4960 - acc: 0.5763 - val_loss: 2.1568 - val_acc: 0.4981\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3514 - acc: 0.4766\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.4916 - acc: 0.5773 - val_loss: 2.3514 - val_acc: 0.4766\n",
            "Completed saving weights iter 27\n",
            "saved History iter 27\n",
            "---------------------Epoch ::  28\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.0877 - acc: 0.5069\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.4769 - acc: 0.5798 - val_loss: 2.0877 - val_acc: 0.5069\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1457 - acc: 0.4998\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.4722 - acc: 0.5816 - val_loss: 2.1457 - val_acc: 0.4998\n",
            "Completed saving weights iter 28\n",
            "saved History iter 28\n",
            "---------------------Epoch ::  29\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1446 - acc: 0.5081\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.4484 - acc: 0.5892 - val_loss: 2.1446 - val_acc: 0.5081\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2412 - acc: 0.4883\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.4309 - acc: 0.5923 - val_loss: 2.2412 - val_acc: 0.4883\n",
            "Completed saving weights iter 29\n",
            "saved History iter 29\n",
            "---------------------Epoch ::  30\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1475 - acc: 0.5095\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.4226 - acc: 0.5951 - val_loss: 2.1475 - val_acc: 0.5095\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3043 - acc: 0.4927\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.4059 - acc: 0.5990 - val_loss: 2.3043 - val_acc: 0.4927\n",
            "Completed saving weights iter 30\n",
            "saved History iter 30\n",
            "---------------------Epoch ::  31\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2511 - acc: 0.4981\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3991 - acc: 0.6014 - val_loss: 2.2511 - val_acc: 0.4981\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1951 - acc: 0.5109\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3831 - acc: 0.6040 - val_loss: 2.1951 - val_acc: 0.5109\n",
            "Completed saving weights iter 31\n",
            "saved History iter 31\n",
            "---------------------Epoch ::  32\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3011 - acc: 0.4962\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.3784 - acc: 0.6054 - val_loss: 2.3011 - val_acc: 0.4962\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.1442 - acc: 0.5210\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3659 - acc: 0.6071 - val_loss: 2.1442 - val_acc: 0.5210\n",
            "Completed saving weights iter 32\n",
            "saved History iter 32\n",
            "---------------------Epoch ::  33\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3221 - acc: 0.5016\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.3436 - acc: 0.6146 - val_loss: 2.3221 - val_acc: 0.5016\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.6730 - acc: 0.4556\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3362 - acc: 0.6148 - val_loss: 2.6730 - val_acc: 0.4556\n",
            "Completed saving weights iter 33\n",
            "saved History iter 33\n",
            "---------------------Epoch ::  34\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.2485 - acc: 0.5063\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3389 - acc: 0.6170 - val_loss: 2.2485 - val_acc: 0.5063\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 2.8516 - acc: 0.4326\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3193 - acc: 0.6214 - val_loss: 2.8516 - val_acc: 0.4326\n",
            "Completed saving weights iter 34\n",
            "saved History iter 34\n",
            "---------------------Epoch ::  35\n",
            "Epoch 1/2\n",
            " 520/1563 [========>.....................] - ETA: 1:07 - loss: 1.2597 - acc: 0.6353"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b7ByEvW819C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "DO not run this code ------for reference only\n",
        "{model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "#----------------Augmentation 1 --------------------\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "#----------------Augmentation 2 --------------------\n",
        "aug = ImageDataGenerator(rotation_range=45, zoom_range=0.4,\n",
        "\twidth_shift_range=0.4, height_shift_range=0.4, shear_range=0.25,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "}\n",
        "\n",
        "#----------------Augmentation 3 --------------------\n",
        "rescaling\n",
        "aug = ImageDataGenerator(rescale=1./255,rotation_range=45, zoom_range=0.4,\n",
        "\twidth_shift_range=0.4, height_shift_range=0.4, shear_range=0.25,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        " \n",
        "testaug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#----------------Augmentation 4 --------------------\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIfKlOFbW9xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}